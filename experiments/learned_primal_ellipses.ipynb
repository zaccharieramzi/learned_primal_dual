{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking GPU(s) 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Learned primal method.\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import adler\n",
    "adler.util.gpu.setup_one_gpu()\n",
    "\n",
    "from adler.odl.phantom import random_phantom\n",
    "from adler.tensorflow import prelu, cosine_decay\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import odl\n",
    "import odl.contrib.tensorflow\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "name = \"learned-primal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define odl stuff\n",
    "# Create ODL data structures\n",
    "size = 128\n",
    "space = odl.uniform_discr([-64, -64], [64, 64], [size, size],\n",
    "                          dtype='float32')\n",
    "\n",
    "geometry = odl.tomo.parallel_beam_geometry(space, num_angles=30)\n",
    "operator = odl.tomo.RayTransform(space, geometry)\n",
    "\n",
    "# Ensure operator has fixed operator norm for scale invariance\n",
    "opnorm = odl.power_method_opnorm(operator)\n",
    "operator = (1 / opnorm) * operator\n",
    "\n",
    "# Create tensorflow layer from odl operator\n",
    "odl_op_layer = odl.contrib.tensorflow.as_tensorflow_layer(operator,\n",
    "                                                          'RayTransform')\n",
    "odl_op_layer_adjoint = odl.contrib.tensorflow.as_tensorflow_layer(operator.adjoint,\n",
    "                                                                  'RayTransformAdjoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User selected paramters\n",
    "n_data = 5\n",
    "n_iter = 10\n",
    "n_primal = 5\n",
    "n_dual = 1\n",
    "# tf params\n",
    "print_freq = 100\n",
    "chkpt = False\n",
    "maximum_steps = 100000\n",
    "logs_dir = 'logs_radon'\n",
    "checkpoint_path = 'chkpt_{run_id}'\n",
    "\n",
    "# define dedicated functions\n",
    "def generate_data(validation=False):\n",
    "    \"\"\"Generate a set of random data.\"\"\"\n",
    "    n_generate = 1 if validation else n_data\n",
    "\n",
    "    y_arr = np.empty((n_generate, operator.range.shape[0], operator.range.shape[1], 1), dtype='float32')\n",
    "    x_true_arr = np.empty((n_generate, space.shape[0], space.shape[1], 1), dtype='float32')\n",
    "\n",
    "    for i in range(n_generate):\n",
    "        if validation:\n",
    "            phantom = odl.phantom.shepp_logan(space, True)\n",
    "        else:\n",
    "            phantom = random_phantom(space)\n",
    "        data = operator(phantom)\n",
    "        noisy_data = data + odl.phantom.white_noise(operator.range) * np.mean(np.abs(data)) * 0.05\n",
    "\n",
    "        x_true_arr[i, ..., 0] = phantom\n",
    "        y_arr[i, ..., 0] = noisy_data\n",
    "\n",
    "    return y_arr, x_true_arr\n",
    "\n",
    "def apply_conv(x, filters=32):\n",
    "    return tf.layers.conv2d(x, filters=filters, kernel_size=3, padding='SAME',\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zaccharie/workspace/learned_primal_dual/venv/lib/python3.6/site-packages/odl/contrib/tensorflow/layer.py:103: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-1bba08216ab0>:36: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /home/zaccharie/workspace/learned_primal_dual/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "# define the model\n",
    "with tf.name_scope('placeholders'):\n",
    "    x_true = tf.placeholder(tf.float32, shape=[None, size, size, 1], name=\"x_true\")\n",
    "    y_rt = tf.placeholder(tf.float32, shape=[None, operator.range.shape[0], operator.range.shape[1], 1], name=\"y_rt\")\n",
    "    is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "\n",
    "with tf.name_scope('tomography'):\n",
    "    with tf.name_scope('initial_values'):\n",
    "        primal = tf.concat([tf.zeros_like(x_true)] * n_primal, axis=-1)\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        with tf.variable_scope('dual_iterate_{}'.format(i)):\n",
    "            evalop = odl_op_layer(primal[..., 1:2])\n",
    "            dual = evalop - y_rt\n",
    "\n",
    "        with tf.variable_scope('primal_iterate_{}'.format(i)):\n",
    "            evalop = odl_op_layer_adjoint(dual[..., 0:1])\n",
    "            update = tf.concat([primal, evalop], axis=-1)\n",
    "\n",
    "            update = prelu(apply_conv(update), name='prelu_1')\n",
    "            update = prelu(apply_conv(update), name='prelu_2')\n",
    "            update = apply_conv(update, filters=n_primal)\n",
    "            primal = primal + update\n",
    "\n",
    "    x_result = primal[..., 0:1]\n",
    "\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    residual = x_result - x_true\n",
    "    squared_error = residual ** 2\n",
    "    loss = tf.reduce_mean(squared_error)\n",
    "\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    # Learning rate\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 1e-3\n",
    "    learning_rate = cosine_decay(starter_learning_rate,\n",
    "                                 global_step,\n",
    "                                 maximum_steps,\n",
    "                                 name='learning_rate')\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        opt_func = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                          beta2=0.99)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), 1)\n",
    "        optimizer = opt_func.apply_gradients(zip(grads, tvars),\n",
    "                                             global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summaries\n",
    "# tensorboard --logdir=...\n",
    "run_id = str(int(time.time()))\n",
    "\n",
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('psnr', -10 * tf.log(loss) / tf.log(10.0))\n",
    "\n",
    "    tf.summary.image('x_result', x_result, max_outputs=n_data)\n",
    "    tf.summary.image('x_true', x_true, max_outputs=n_data)\n",
    "    tf.summary.image('squared_error', squared_error, max_outputs=n_data)\n",
    "    tf.summary.image('residual', residual, max_outputs=n_data)\n",
    "\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    test_summary_writer = tf.summary.FileWriter(logs_dir + f'/test_{run_id}')\n",
    "    train_summary_writer = tf.summary.FileWriter(logs_dir + f'/train_{run_id}', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faad68d730234210baac2c0297b81f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100, loss=0.013401556760072708\n",
      "iter=200, loss=0.009856192395091057\n",
      "iter=300, loss=0.009816672652959824\n",
      "iter=400, loss=0.013956650160253048\n",
      "iter=500, loss=0.009177898988127708\n",
      "iter=600, loss=0.007365264929831028\n",
      "iter=700, loss=0.00783451460301876\n",
      "iter=800, loss=0.006058550905436277\n",
      "iter=900, loss=0.005195289850234985\n",
      "iter=1000, loss=0.004707389511168003\n",
      "iter=1100, loss=0.005421053152531385\n",
      "iter=1200, loss=0.004818640649318695\n",
      "iter=1300, loss=0.0063102710992097855\n",
      "iter=1400, loss=0.0060930922627449036\n",
      "iter=1500, loss=0.0038196039386093616\n",
      "iter=1600, loss=0.003832656191661954\n",
      "iter=1700, loss=0.004254722036421299\n",
      "iter=1800, loss=0.004779539071023464\n",
      "iter=1900, loss=0.0034136828035116196\n",
      "iter=2000, loss=0.002609821269288659\n",
      "iter=2100, loss=0.003618695307523012\n",
      "iter=2200, loss=0.002771900501102209\n",
      "iter=2300, loss=0.002542594913393259\n",
      "iter=2400, loss=0.0029977248050272465\n",
      "iter=2500, loss=0.0025201523676514626\n",
      "iter=2600, loss=0.0027549811638891697\n",
      "iter=2700, loss=0.0018051951192319393\n",
      "iter=2800, loss=0.0026448536664247513\n",
      "iter=2900, loss=0.001997017301619053\n",
      "iter=3000, loss=0.002054975600913167\n",
      "iter=3100, loss=0.002203471027314663\n",
      "iter=3200, loss=0.0018437635153532028\n",
      "iter=3300, loss=0.002332399133592844\n",
      "iter=3400, loss=0.0023827836848795414\n",
      "iter=3500, loss=0.001397771411575377\n",
      "iter=3600, loss=0.001529546221718192\n",
      "iter=3700, loss=0.001979473978281021\n",
      "iter=3800, loss=0.001618215348571539\n",
      "iter=3900, loss=0.001481414888985455\n",
      "iter=4000, loss=0.0016138919163495302\n",
      "iter=4100, loss=0.0014446143759414554\n",
      "iter=4200, loss=0.00218072603456676\n",
      "iter=4300, loss=0.004027999471873045\n",
      "iter=4400, loss=0.0018764468841254711\n",
      "iter=4500, loss=0.002226823940873146\n",
      "iter=4600, loss=0.0013468463439494371\n",
      "iter=4700, loss=0.002123091835528612\n",
      "iter=4800, loss=0.0015636046882718801\n",
      "iter=4900, loss=0.0020379710476845503\n",
      "iter=5000, loss=0.0012570976978167892\n",
      "iter=5100, loss=0.0013964513782411814\n",
      "iter=5200, loss=0.0021508722566068172\n",
      "iter=5300, loss=0.0018481849692761898\n",
      "iter=5400, loss=0.0023802381474524736\n",
      "iter=5500, loss=0.0012127184309065342\n",
      "iter=5600, loss=0.001235311385244131\n",
      "iter=5700, loss=0.001676051178947091\n",
      "iter=5800, loss=0.0015257160412147641\n",
      "iter=5900, loss=0.0015561694744974375\n",
      "iter=6000, loss=0.0011131352512165904\n",
      "iter=6100, loss=0.0018841902492567897\n",
      "iter=6200, loss=0.0010033423313871026\n",
      "iter=6300, loss=0.001165064051747322\n",
      "iter=6400, loss=0.0016726222820580006\n",
      "iter=6500, loss=0.0014520145487040281\n",
      "iter=6600, loss=0.0013202240224927664\n",
      "iter=6700, loss=0.0014006958808749914\n",
      "iter=6800, loss=0.0017218512948602438\n",
      "iter=6900, loss=0.0014244831399992108\n",
      "iter=7000, loss=0.0019177154172211885\n",
      "iter=7100, loss=0.0010827801888808608\n",
      "iter=7200, loss=0.001533478731289506\n",
      "iter=7300, loss=0.0010112498421221972\n",
      "iter=7400, loss=0.0014227511128410697\n",
      "iter=7500, loss=0.001579762203618884\n",
      "iter=7600, loss=0.001197807490825653\n",
      "iter=7700, loss=0.0021097478456795216\n",
      "iter=7800, loss=0.0010044558439403772\n",
      "iter=7900, loss=0.0010287284385412931\n",
      "iter=8000, loss=0.0009372537024319172\n",
      "iter=8100, loss=0.0009450116194784641\n",
      "iter=8200, loss=0.0011058893287554383\n",
      "iter=8300, loss=0.0009704616386443377\n",
      "iter=8400, loss=0.0010932062286883593\n",
      "iter=8500, loss=0.0009562126942910254\n",
      "iter=8600, loss=0.0014300054172053933\n",
      "iter=8700, loss=0.0009735087514854968\n",
      "iter=8800, loss=0.0012223382946103811\n",
      "iter=8900, loss=0.0009816447272896767\n",
      "iter=9000, loss=0.001203910680487752\n",
      "iter=9100, loss=0.0009870067005977035\n",
      "iter=9200, loss=0.001078476314432919\n",
      "iter=9300, loss=0.0007968886056914926\n",
      "iter=9400, loss=0.0007948376005515456\n",
      "iter=9500, loss=0.0010213308269158006\n",
      "iter=9600, loss=0.001179737620986998\n",
      "iter=9700, loss=0.0011422057868912816\n",
      "iter=9800, loss=0.0008762649958953261\n",
      "iter=9900, loss=0.001243698876351118\n",
      "iter=10000, loss=0.0009886063635349274\n",
      "iter=10100, loss=0.0008309255354106426\n",
      "iter=10200, loss=0.0007402859628200531\n",
      "iter=10300, loss=0.001051631523296237\n",
      "iter=10400, loss=0.0011384013341739774\n",
      "iter=10500, loss=0.0009570434922352433\n",
      "iter=10600, loss=0.0007982957758940756\n",
      "iter=10700, loss=0.0007832956034690142\n",
      "iter=10800, loss=0.0008355316240340471\n",
      "iter=10900, loss=0.0007968031568452716\n",
      "iter=11000, loss=0.0007531913579441607\n",
      "iter=11100, loss=0.0010641715489327908\n",
      "iter=11200, loss=0.0010140667436644435\n",
      "iter=11300, loss=0.0007710019126534462\n",
      "iter=11400, loss=0.0006933675613254309\n",
      "iter=11500, loss=0.0008943272987380624\n",
      "iter=11600, loss=0.0007077615009620786\n",
      "iter=11700, loss=0.0009942051256075501\n",
      "iter=11800, loss=0.0009568763780407608\n",
      "iter=11900, loss=0.0009776726365089417\n",
      "iter=12000, loss=0.0009685520199127495\n",
      "iter=12100, loss=0.0007606548024341464\n",
      "iter=12200, loss=0.0007738560670986772\n",
      "iter=12300, loss=0.0008059482206590474\n",
      "iter=12400, loss=0.0006731581524945796\n",
      "iter=12500, loss=0.0008490568725392222\n",
      "iter=12600, loss=0.0008623801986686885\n",
      "iter=12700, loss=0.0007954713073559105\n",
      "iter=12800, loss=0.0007748801726847887\n",
      "iter=12900, loss=0.0009137409506365657\n",
      "iter=13000, loss=0.0009182870853692293\n",
      "iter=13100, loss=0.0010050192940980196\n",
      "iter=13200, loss=0.0009746100404299796\n",
      "iter=13300, loss=0.0006911942036822438\n",
      "iter=13400, loss=0.000969178625382483\n",
      "iter=13500, loss=0.0009447158081457019\n",
      "iter=13600, loss=0.0010350254597142339\n",
      "iter=13700, loss=0.0010245584417134523\n",
      "iter=13800, loss=0.000823338283225894\n",
      "iter=13900, loss=0.0007836455479264259\n",
      "iter=14000, loss=0.0007610148168168962\n",
      "iter=14100, loss=0.0006490938831120729\n",
      "iter=14200, loss=0.0007111707236617804\n",
      "iter=14300, loss=0.0006927105132490396\n",
      "iter=14400, loss=0.0005906379083171487\n",
      "iter=14500, loss=0.0009247383568435907\n",
      "iter=14600, loss=0.0007377717993222177\n",
      "iter=14700, loss=0.0006857654079794884\n",
      "iter=14800, loss=0.00093702576123178\n",
      "iter=14900, loss=0.000702376535627991\n",
      "iter=15000, loss=0.0007894246373325586\n",
      "iter=15100, loss=0.0007794147823005915\n",
      "iter=15200, loss=0.0008728023385629058\n",
      "iter=15300, loss=0.0008032783516682684\n",
      "iter=15400, loss=0.0006686989217996597\n",
      "iter=15500, loss=0.000947984226513654\n",
      "iter=15600, loss=0.0011107249883934855\n",
      "iter=15700, loss=0.0006683483952656388\n",
      "iter=15800, loss=0.0008288532262668014\n",
      "iter=15900, loss=0.0009510776726529002\n",
      "iter=16000, loss=0.000685658014845103\n",
      "iter=16100, loss=0.00056858902098611\n",
      "iter=16200, loss=0.000749745056964457\n",
      "iter=16300, loss=0.0007193817291408777\n",
      "iter=16400, loss=0.0008718381286598742\n",
      "iter=16500, loss=0.0006919073639437556\n",
      "iter=16600, loss=0.000781246752012521\n",
      "iter=16700, loss=0.0006182062206789851\n",
      "iter=16800, loss=0.0008346941322088242\n",
      "iter=16900, loss=0.0005222868057899177\n",
      "iter=17000, loss=0.0006039545405656099\n",
      "iter=17100, loss=0.0007910608546808362\n",
      "iter=17200, loss=0.0008742075879126787\n",
      "iter=17300, loss=0.000819738139398396\n",
      "iter=17400, loss=0.0005787617992609739\n",
      "iter=17500, loss=0.0006396028911694884\n",
      "iter=17600, loss=0.0006286438438110054\n",
      "iter=17700, loss=0.0005936670931987464\n",
      "iter=17800, loss=0.00048075546510517597\n",
      "iter=17900, loss=0.0006920714513398707\n",
      "iter=18000, loss=0.0005938163376413286\n",
      "iter=18100, loss=0.0006397572578862309\n",
      "iter=18200, loss=0.0007721693255007267\n",
      "iter=18300, loss=0.0007228972972370684\n",
      "iter=18400, loss=0.000583760323934257\n",
      "iter=18500, loss=0.0006409378256648779\n",
      "iter=18600, loss=0.0006489972583949566\n",
      "iter=18700, loss=0.0005079798283986747\n",
      "iter=18800, loss=0.0006471587112173438\n",
      "iter=18900, loss=0.0006302119581960142\n",
      "iter=19000, loss=0.0005996214458718896\n",
      "iter=19100, loss=0.0006509424420073628\n",
      "iter=19200, loss=0.0034363726153969765\n",
      "iter=19300, loss=0.0006629416020587087\n",
      "iter=19400, loss=0.000672670139465481\n",
      "iter=19500, loss=0.0005879583186469972\n",
      "iter=19600, loss=0.0007160180830396712\n",
      "iter=19700, loss=0.0006133221904747188\n",
      "iter=19800, loss=0.0004853834107052535\n",
      "iter=19900, loss=0.0006646752590313554\n",
      "iter=20000, loss=0.0006855008541606367\n",
      "iter=20100, loss=0.0006373877404257655\n",
      "iter=20200, loss=0.0005668285302817822\n",
      "iter=20300, loss=0.0013080707285553217\n",
      "iter=20400, loss=0.0008738909964449704\n",
      "iter=20500, loss=0.0008317073807120323\n",
      "iter=20600, loss=0.0007823979249224067\n",
      "iter=20700, loss=0.000509523437358439\n",
      "iter=20800, loss=0.0005661617615260184\n",
      "iter=20900, loss=0.0005146281328052282\n",
      "iter=21000, loss=0.0005353113519959152\n",
      "iter=21100, loss=0.0005384046235121787\n",
      "iter=21200, loss=0.0005452487384900451\n",
      "iter=21300, loss=0.0007551121525466442\n",
      "iter=21400, loss=0.0004670688067562878\n",
      "iter=21500, loss=0.0005005390848964453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=21600, loss=0.0005254679708741605\n",
      "iter=21700, loss=0.0006342025008052588\n",
      "iter=21800, loss=0.0004963738610967994\n",
      "iter=21900, loss=0.0005737472674809396\n",
      "iter=22000, loss=0.0005647923098877072\n",
      "iter=22100, loss=0.0006720967940054834\n",
      "iter=22200, loss=0.0005625277990475297\n",
      "iter=22300, loss=0.0007540753576904535\n",
      "iter=22400, loss=0.000638811441604048\n",
      "iter=22500, loss=0.0005314939189702272\n",
      "iter=22600, loss=0.0005919551476836205\n",
      "iter=22700, loss=0.0005256544682197273\n",
      "iter=22800, loss=0.0006311449105851352\n",
      "iter=22900, loss=0.0005239403108134866\n",
      "iter=23000, loss=0.000654612435027957\n",
      "iter=23100, loss=0.0009409851627424359\n",
      "iter=23200, loss=0.0006053365068510175\n",
      "iter=23300, loss=0.00053225620649755\n",
      "iter=23400, loss=0.0005489299073815346\n",
      "iter=23500, loss=0.00047325441846624017\n",
      "iter=23600, loss=0.0006655040197074413\n",
      "iter=23700, loss=0.0005751101416535676\n",
      "iter=23800, loss=0.0005957772955298424\n",
      "iter=23900, loss=0.000539942120667547\n",
      "iter=24000, loss=0.0005606257473118603\n",
      "iter=24100, loss=0.0005088022444397211\n",
      "iter=24200, loss=0.0005728309624828398\n",
      "iter=24300, loss=0.0005870150635018945\n",
      "iter=24400, loss=0.0005418597138486803\n",
      "iter=24500, loss=0.0005490903276950121\n",
      "iter=24600, loss=0.0007003211067058146\n",
      "iter=24700, loss=0.000602732237894088\n",
      "iter=24800, loss=0.00040190195431932807\n",
      "iter=24900, loss=0.0006539460737258196\n",
      "iter=25000, loss=0.000458478054497391\n",
      "iter=25100, loss=0.0005365087417885661\n",
      "iter=25200, loss=0.0006136497249826789\n",
      "iter=25300, loss=0.000584181398153305\n",
      "iter=25400, loss=0.0005800207145512104\n",
      "iter=25500, loss=0.00045366352424025536\n",
      "iter=25600, loss=0.0004656200180761516\n",
      "iter=25700, loss=0.0005572703084908426\n",
      "iter=25800, loss=0.0004960565129294991\n",
      "iter=25900, loss=0.00043008881038986146\n",
      "iter=26000, loss=0.0007008826360106468\n",
      "iter=26100, loss=0.000608225236646831\n",
      "iter=26200, loss=0.00046398123959079385\n",
      "iter=26300, loss=0.0005076087545603514\n",
      "iter=26400, loss=0.0004737569543067366\n",
      "iter=26500, loss=0.00046672701137140393\n",
      "iter=26600, loss=0.00047088690917007625\n",
      "iter=26700, loss=0.00046530301915481687\n",
      "iter=26800, loss=0.0006168015534058213\n",
      "iter=26900, loss=0.00048411128227598965\n",
      "iter=27000, loss=0.0004192665219306946\n",
      "iter=27100, loss=0.0005389942089095712\n",
      "iter=27200, loss=0.0013720636488869786\n",
      "iter=27300, loss=0.0005338069749996066\n",
      "iter=27400, loss=0.0003631945000961423\n",
      "iter=27500, loss=0.0005100469570606947\n",
      "iter=27600, loss=0.0005912286578677595\n",
      "iter=27700, loss=0.00040878719300962985\n",
      "iter=27800, loss=0.0005730002885684371\n",
      "iter=27900, loss=0.0004236976965330541\n",
      "iter=28000, loss=0.0004473439767025411\n",
      "iter=28100, loss=0.0006635341560468078\n",
      "iter=28200, loss=0.00037063765921629965\n",
      "iter=28300, loss=0.0005590556538663805\n",
      "iter=28400, loss=0.0004444429068826139\n",
      "iter=28500, loss=0.0005784225068055093\n",
      "iter=28600, loss=0.0006267182761803269\n",
      "iter=28700, loss=0.00043814253876917064\n",
      "iter=28800, loss=0.0004212986386846751\n",
      "iter=28900, loss=0.0005269593093544245\n",
      "iter=29000, loss=0.00042707682587206364\n",
      "iter=29100, loss=0.0003795510856434703\n",
      "iter=29200, loss=0.0005576384719461203\n",
      "iter=29300, loss=0.0004884239751845598\n",
      "iter=29400, loss=0.0009153379360213876\n",
      "iter=29500, loss=0.0005492654163390398\n",
      "iter=29600, loss=0.00042002531699836254\n",
      "iter=29700, loss=0.0004413881979417056\n",
      "iter=29800, loss=0.0003717019280884415\n",
      "iter=29900, loss=0.000392891961382702\n",
      "iter=30000, loss=0.0005601329612545669\n",
      "iter=30100, loss=0.00043879917939193547\n",
      "iter=30200, loss=0.00046343967551365495\n",
      "iter=30300, loss=0.00034620967926457524\n",
      "iter=30400, loss=0.00042322513763792813\n",
      "iter=30500, loss=0.00039005433791317046\n",
      "iter=30600, loss=0.000396767514757812\n",
      "iter=30700, loss=0.0006897493731230497\n",
      "iter=30800, loss=0.000600248109549284\n",
      "iter=30900, loss=0.0005094825755804777\n",
      "iter=31000, loss=0.00041971748578362167\n",
      "iter=31100, loss=0.0005362277152016759\n",
      "iter=31200, loss=0.0006223895470611751\n",
      "iter=31300, loss=0.0003580262418836355\n",
      "iter=31400, loss=0.00036501477006822824\n",
      "iter=31500, loss=0.00034600403159856796\n",
      "iter=31600, loss=0.0004999247030355036\n",
      "iter=31700, loss=0.0004043172230012715\n",
      "iter=31800, loss=0.0004762608150485903\n",
      "iter=31900, loss=0.00037834738031961024\n",
      "iter=32000, loss=0.0003835047536995262\n",
      "iter=32100, loss=0.0003647673293016851\n",
      "iter=32200, loss=0.00040152837755158544\n",
      "iter=32300, loss=0.0004047352122142911\n",
      "iter=32400, loss=0.0004017714236397296\n",
      "iter=32500, loss=0.0003277190844528377\n",
      "iter=32600, loss=0.00045918356045149267\n",
      "iter=32700, loss=0.000486928503960371\n",
      "iter=32800, loss=0.0005058860406279564\n",
      "iter=32900, loss=0.00042702892096713185\n",
      "iter=33000, loss=0.00043859047582373023\n",
      "iter=33100, loss=0.000464307056972757\n",
      "iter=33200, loss=0.00041002006037160754\n",
      "iter=33300, loss=0.00043994002044200897\n",
      "iter=33400, loss=0.0004438334726728499\n",
      "iter=33500, loss=0.0004950809525325894\n",
      "iter=33600, loss=0.00044868412078358233\n",
      "iter=33700, loss=0.00039097998524084687\n",
      "iter=33800, loss=0.0004078293277416378\n",
      "iter=33900, loss=0.0004876140155829489\n",
      "iter=34000, loss=0.0004175133944954723\n",
      "iter=34100, loss=0.0005019025411456823\n",
      "iter=34200, loss=0.0004091532318852842\n",
      "iter=34300, loss=0.0004302281595300883\n",
      "iter=34400, loss=0.00040831766091287136\n",
      "iter=34500, loss=0.000516376516316086\n",
      "iter=34600, loss=0.0006396500975824893\n",
      "iter=34700, loss=0.0005570317734964192\n",
      "iter=34800, loss=0.0003886425110977143\n",
      "iter=34900, loss=0.00048392347525805235\n",
      "iter=35000, loss=0.0007292218506336212\n",
      "iter=35100, loss=0.00042844953713938594\n",
      "iter=35200, loss=0.0004066835099365562\n",
      "iter=35300, loss=0.0003276849747635424\n",
      "iter=35400, loss=0.00045550588401965797\n",
      "iter=35500, loss=0.00039401307003572583\n",
      "iter=35600, loss=0.0004284016613382846\n",
      "iter=35700, loss=0.00040083026397041976\n",
      "iter=35800, loss=0.0004562971880659461\n",
      "iter=35900, loss=0.00040469193481840193\n",
      "iter=36000, loss=0.0003415311221033335\n",
      "iter=36100, loss=0.00046622828813269734\n",
      "iter=36200, loss=0.00040573824662715197\n",
      "iter=36300, loss=0.0004016341408714652\n",
      "iter=36400, loss=0.0005350480205379426\n",
      "iter=36500, loss=0.00047676387475803494\n",
      "iter=36600, loss=0.00041538424557074904\n",
      "iter=36700, loss=0.0003899469447787851\n",
      "iter=36800, loss=0.00043294974602758884\n",
      "iter=36900, loss=0.0007147436263039708\n",
      "iter=37000, loss=0.0004093990719411522\n",
      "iter=37100, loss=0.00034354219678789377\n",
      "iter=37200, loss=0.0003821064601652324\n",
      "iter=37300, loss=0.00031334589584730566\n",
      "iter=37400, loss=0.0003431507502682507\n",
      "iter=37500, loss=0.0003378968685865402\n",
      "iter=37600, loss=0.0003702365793287754\n",
      "iter=37700, loss=0.0003982477937825024\n",
      "iter=37800, loss=0.0004763866600114852\n",
      "iter=37900, loss=0.00034068519016727805\n",
      "iter=38000, loss=0.00041051252628676593\n",
      "iter=38100, loss=0.0005308674881234765\n",
      "iter=38200, loss=0.0004891286371275783\n",
      "iter=38300, loss=0.00042091115028597414\n",
      "iter=38400, loss=0.00030816279468126595\n",
      "iter=38500, loss=0.0003924501361325383\n",
      "iter=38600, loss=0.00035154991201125085\n",
      "iter=38700, loss=0.00034934404538944364\n",
      "iter=38800, loss=0.0003799720434471965\n",
      "iter=38900, loss=0.00036035344237461686\n",
      "iter=39000, loss=0.00035256752744317055\n",
      "iter=39100, loss=0.0003575741429813206\n",
      "iter=39200, loss=0.0005035501671954989\n",
      "iter=39300, loss=0.0005657061701640487\n",
      "iter=39400, loss=0.0003689302538987249\n",
      "iter=39500, loss=0.00046332913916558027\n",
      "iter=39600, loss=0.0006781190168112516\n",
      "iter=39700, loss=0.0004695892857853323\n",
      "iter=39800, loss=0.0003915567649528384\n",
      "iter=39900, loss=0.0003819613775704056\n",
      "iter=40000, loss=0.0002968289190903306\n",
      "iter=40100, loss=0.0004421802004799247\n",
      "iter=40200, loss=0.00043155968887731433\n",
      "iter=40300, loss=0.0004929263959638774\n",
      "iter=40400, loss=0.0003121492627542466\n",
      "iter=40500, loss=0.0004167549777776003\n",
      "iter=40600, loss=0.0003256594645790756\n",
      "iter=40700, loss=0.0003377017565071583\n",
      "iter=40800, loss=0.0003238614881411195\n",
      "iter=40900, loss=0.0003337088564876467\n",
      "iter=41000, loss=0.00037612183950841427\n",
      "iter=41100, loss=0.0003496765857562423\n",
      "iter=41200, loss=0.00044786048238165677\n",
      "iter=41300, loss=0.000345225736964494\n",
      "iter=41400, loss=0.00035201827995479107\n",
      "iter=41500, loss=0.00045981950825080276\n",
      "iter=41600, loss=0.00047667755279690027\n",
      "iter=41700, loss=0.0003428176569286734\n",
      "iter=41800, loss=0.0002984721795655787\n",
      "iter=41900, loss=0.000452061474788934\n",
      "iter=42000, loss=0.0004203125718049705\n",
      "iter=42100, loss=0.00037157765473239124\n",
      "iter=42200, loss=0.0003074747510254383\n",
      "iter=42300, loss=0.00040375743992626667\n",
      "iter=42400, loss=0.00030268472619354725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=42500, loss=0.0003168671391904354\n",
      "iter=42600, loss=0.00037690604222007096\n",
      "iter=42700, loss=0.0003860926954075694\n",
      "iter=42800, loss=0.0003092371625825763\n",
      "iter=42900, loss=0.0004397864977363497\n",
      "iter=43000, loss=0.0003380870330147445\n",
      "iter=43100, loss=0.00032736663706600666\n",
      "iter=43200, loss=0.00030836043879389763\n",
      "iter=43300, loss=0.0004063511732965708\n",
      "iter=43400, loss=0.0004177007940597832\n",
      "iter=43500, loss=0.00036302220541983843\n",
      "iter=43600, loss=0.00041245363536290824\n",
      "iter=43700, loss=0.0003430037177167833\n",
      "iter=43800, loss=0.00034489939571358263\n",
      "iter=43900, loss=0.00038762204349040985\n",
      "iter=44000, loss=0.00032269611256197095\n",
      "iter=44100, loss=0.00031701874104328454\n",
      "iter=44200, loss=0.0004047924594487995\n",
      "iter=44300, loss=0.00038702855817973614\n",
      "iter=44400, loss=0.0004595720674842596\n",
      "iter=44500, loss=0.0003645707620307803\n",
      "iter=44600, loss=0.0005042238044552505\n",
      "iter=44700, loss=0.0004185682046227157\n",
      "iter=44800, loss=0.00032745327916927636\n",
      "iter=44900, loss=0.0005034086061641574\n",
      "iter=45000, loss=0.00042648386443033814\n",
      "iter=45100, loss=0.0003375324886292219\n",
      "iter=45200, loss=0.00037169791175983846\n",
      "iter=45300, loss=0.0003866672341246158\n",
      "iter=45400, loss=0.00034574625897221267\n",
      "iter=45500, loss=0.0005064530414529145\n",
      "iter=45600, loss=0.00042227492667734623\n",
      "iter=45700, loss=0.00036710104905068874\n",
      "iter=45800, loss=0.00028726551681756973\n",
      "iter=45900, loss=0.00027818098897114396\n",
      "iter=46000, loss=0.00038613006472587585\n",
      "iter=46100, loss=0.000427494989708066\n",
      "iter=46200, loss=0.0005499166436493397\n",
      "iter=46300, loss=0.00037763320142403245\n",
      "iter=46400, loss=0.0003995085717178881\n",
      "iter=46500, loss=0.00038328603841364384\n",
      "iter=46600, loss=0.0003635021857917309\n",
      "iter=46700, loss=0.0003071206738241017\n",
      "iter=46800, loss=0.00037866277853026986\n",
      "iter=46900, loss=0.0003702712128870189\n",
      "iter=47000, loss=0.00034801734727807343\n",
      "iter=47100, loss=0.0003098426677752286\n",
      "iter=47200, loss=0.0009198792977258563\n",
      "iter=47300, loss=0.0003804762673098594\n",
      "iter=47400, loss=0.00031172577291727066\n",
      "iter=47500, loss=0.0003710219752974808\n",
      "iter=47600, loss=0.0003826316969934851\n",
      "iter=47700, loss=0.00034016609424725175\n",
      "iter=47800, loss=0.000381306279450655\n",
      "iter=47900, loss=0.00028393417596817017\n",
      "iter=48000, loss=0.00035045784898102283\n",
      "iter=48100, loss=0.00043634348548948765\n",
      "iter=48200, loss=0.0003064381016883999\n",
      "iter=48300, loss=0.0003520128666423261\n",
      "iter=48400, loss=0.0003558275639079511\n",
      "iter=48500, loss=0.00032940326491370797\n",
      "iter=48600, loss=0.0003135251463390887\n",
      "iter=48700, loss=0.0003251907473895699\n",
      "iter=48800, loss=0.00029473251197487116\n",
      "iter=48900, loss=0.0003584415535442531\n",
      "iter=49000, loss=0.0004660370759665966\n",
      "iter=49100, loss=0.0002662730112206191\n",
      "iter=49200, loss=0.00026084278943017125\n",
      "iter=49300, loss=0.0002789451100397855\n",
      "iter=49400, loss=0.0003596970345824957\n",
      "iter=49500, loss=0.00033230165718123317\n",
      "iter=49600, loss=0.00029983726562932134\n",
      "iter=49700, loss=0.0003585059312172234\n",
      "iter=49800, loss=0.00026349182007834315\n",
      "iter=49900, loss=0.0005522374995052814\n",
      "iter=50000, loss=0.0003127336094621569\n",
      "iter=50100, loss=0.0004167688894085586\n",
      "iter=50200, loss=0.00029638479463756084\n",
      "iter=50300, loss=0.00035929420846514404\n",
      "iter=50400, loss=0.00028933174326084554\n",
      "iter=50500, loss=0.00032779230969026685\n",
      "iter=50600, loss=0.00031030859099701047\n",
      "iter=50700, loss=0.0003260577213950455\n",
      "iter=50800, loss=0.0004319831496104598\n",
      "iter=50900, loss=0.0005576371913775802\n",
      "iter=51000, loss=0.00030428642639890313\n",
      "iter=51100, loss=0.0002899965620599687\n",
      "iter=51200, loss=0.0004214589425828308\n",
      "iter=51300, loss=0.0003837365657091141\n",
      "iter=51400, loss=0.00035611484781838953\n",
      "iter=51500, loss=0.0002611537929624319\n",
      "iter=51600, loss=0.00034357066033408046\n",
      "iter=51700, loss=0.0003248983121011406\n",
      "iter=51800, loss=0.00037116481689736247\n",
      "iter=51900, loss=0.0003420184657443315\n",
      "iter=52000, loss=0.0003146837407257408\n",
      "iter=52100, loss=0.00033736403565853834\n",
      "iter=52200, loss=0.0003044850891456008\n",
      "iter=52300, loss=0.00031578863854520023\n",
      "iter=52400, loss=0.0002912496274802834\n",
      "iter=52500, loss=0.00042065425077453256\n",
      "iter=52600, loss=0.00038093444891273975\n",
      "iter=52700, loss=0.0003449927899055183\n",
      "iter=52800, loss=0.00043241240200586617\n",
      "iter=52900, loss=0.0003091686812695116\n",
      "iter=53000, loss=0.0002958335098810494\n",
      "iter=53100, loss=0.00027396826772019267\n",
      "iter=53200, loss=0.00034764991141855717\n",
      "iter=53300, loss=0.00030160133610479534\n",
      "iter=53400, loss=0.00028368073981255293\n",
      "iter=53500, loss=0.00028726906748488545\n",
      "iter=53600, loss=0.0003099733730778098\n",
      "iter=53700, loss=0.00030983606120571494\n",
      "iter=53800, loss=0.00040394539246335626\n",
      "iter=53900, loss=0.000316430174279958\n",
      "iter=54000, loss=0.0003084009513258934\n",
      "iter=54100, loss=0.0003183828084729612\n",
      "iter=54200, loss=0.0003110274556092918\n",
      "iter=54300, loss=0.00034866182249970734\n",
      "iter=54400, loss=0.0003149834810756147\n",
      "iter=54500, loss=0.00032918323995545506\n",
      "iter=54600, loss=0.00030714774038642645\n",
      "iter=54700, loss=0.00030432906351052225\n",
      "iter=54800, loss=0.0003003036545123905\n",
      "iter=54900, loss=0.0003401609428692609\n",
      "iter=55000, loss=0.0003711914469022304\n",
      "iter=55100, loss=0.0003587906248867512\n",
      "iter=55200, loss=0.0003643044037744403\n",
      "iter=55300, loss=0.0004943747771903872\n",
      "iter=55400, loss=0.00046194420428946614\n",
      "iter=55500, loss=0.00037300889380276203\n",
      "iter=55600, loss=0.0003094046551268548\n",
      "iter=55700, loss=0.0003043802862521261\n",
      "iter=55800, loss=0.00026351178530603647\n",
      "iter=55900, loss=0.0002845600829459727\n",
      "iter=56000, loss=0.0002846759743988514\n",
      "iter=56100, loss=0.0002826592535711825\n",
      "iter=56200, loss=0.0003098041343037039\n",
      "iter=56300, loss=0.0004428136453498155\n",
      "iter=56400, loss=0.0002923014690168202\n",
      "iter=56500, loss=0.000941682024858892\n",
      "iter=56600, loss=0.00033574888948351145\n",
      "iter=56700, loss=0.00029430948779918253\n",
      "iter=56800, loss=0.00025295891100540757\n",
      "iter=56900, loss=0.00036141922464594245\n",
      "iter=57000, loss=0.00029820602503605187\n",
      "iter=57100, loss=0.00027024431619793177\n",
      "iter=57200, loss=0.0003032415406778455\n",
      "iter=57300, loss=0.0002733968722168356\n",
      "iter=57400, loss=0.0003190217539668083\n",
      "iter=57500, loss=0.0003116583393421024\n",
      "iter=57600, loss=0.0002757823094725609\n",
      "iter=57700, loss=0.00034043053165078163\n",
      "iter=57800, loss=0.0002855941711459309\n",
      "iter=57900, loss=0.00031636416679248214\n",
      "iter=58000, loss=0.00037220242666080594\n",
      "iter=58100, loss=0.000356790900696069\n",
      "iter=58200, loss=0.0002988619380630553\n",
      "iter=58300, loss=0.00033669680124148726\n",
      "iter=58400, loss=0.0002893784549087286\n",
      "iter=58500, loss=0.0003074915730394423\n",
      "iter=58600, loss=0.0002707094536162913\n",
      "iter=58700, loss=0.000323738728184253\n",
      "iter=58800, loss=0.0003087292134296149\n",
      "iter=58900, loss=0.00034189672442153096\n",
      "iter=59000, loss=0.00029034732142463326\n",
      "iter=59100, loss=0.0003332415362820029\n",
      "iter=59200, loss=0.00028608430875465274\n",
      "iter=59300, loss=0.00034757607500068843\n",
      "iter=59400, loss=0.0003350088663864881\n",
      "iter=59500, loss=0.00040857100975699723\n",
      "iter=59600, loss=0.00035858387127518654\n",
      "iter=59700, loss=0.0003333588829264045\n",
      "iter=59800, loss=0.00026454724138602614\n",
      "iter=59900, loss=0.0002758447080850601\n",
      "iter=60000, loss=0.00029318209271878004\n",
      "iter=60100, loss=0.00023857332416810095\n",
      "iter=60200, loss=0.00024062336888164282\n",
      "iter=60300, loss=0.00028053479036316276\n",
      "iter=60400, loss=0.00029452895978465676\n",
      "iter=60500, loss=0.0003157879691570997\n",
      "iter=60600, loss=0.00026217399863526225\n",
      "iter=60700, loss=0.0002921048435382545\n",
      "iter=60800, loss=0.00032119773095473647\n",
      "iter=60900, loss=0.00028198922518640757\n",
      "iter=61000, loss=0.00022524871747009456\n",
      "iter=61100, loss=0.0002459309180267155\n",
      "iter=61200, loss=0.000257949810475111\n",
      "iter=61300, loss=0.0002865971764549613\n",
      "iter=61400, loss=0.0003100404283031821\n",
      "iter=61500, loss=0.00031688279705122113\n",
      "iter=61600, loss=0.0002682419726625085\n",
      "iter=61700, loss=0.0002603678440209478\n",
      "iter=61800, loss=0.00034009365481324494\n",
      "iter=61900, loss=0.00022974055900704116\n",
      "iter=62000, loss=0.0002860645763576031\n",
      "iter=62100, loss=0.00025698146782815456\n",
      "iter=62200, loss=0.00022072999854572117\n",
      "iter=62300, loss=0.00029674218967556953\n",
      "iter=62400, loss=0.00030115689150989056\n",
      "iter=62500, loss=0.00030897516990080476\n",
      "iter=62600, loss=0.0002583821478765458\n",
      "iter=62700, loss=0.00038615238736383617\n",
      "iter=62800, loss=0.00025482638739049435\n",
      "iter=62900, loss=0.0002711582346819341\n",
      "iter=63000, loss=0.0002302138163940981\n",
      "iter=63100, loss=0.00031720136757940054\n",
      "iter=63200, loss=0.0002641502651385963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=63300, loss=0.00029139683465473354\n",
      "iter=63400, loss=0.00026550597976893187\n",
      "iter=63500, loss=0.0004021083004772663\n",
      "iter=63600, loss=0.00035487377317622304\n",
      "iter=63700, loss=0.00028605395345948637\n",
      "iter=63800, loss=0.00026130519108846784\n",
      "iter=63900, loss=0.00028575892793014646\n",
      "iter=64000, loss=0.0003083109331782907\n",
      "iter=64100, loss=0.0002518828259781003\n",
      "iter=64200, loss=0.00029543228447437286\n",
      "iter=64300, loss=0.0002535175590310246\n",
      "iter=64400, loss=0.0002527812903281301\n",
      "iter=64500, loss=0.00026042881654575467\n",
      "iter=64600, loss=0.00026173534570261836\n",
      "iter=64700, loss=0.0002718601026572287\n",
      "iter=64800, loss=0.00026283730403520167\n",
      "iter=64900, loss=0.00026587527827359736\n",
      "iter=65000, loss=0.00023845990654081106\n",
      "iter=65100, loss=0.0003091043618042022\n",
      "iter=65200, loss=0.0002860981912817806\n",
      "iter=65300, loss=0.00024070742074400187\n",
      "iter=65400, loss=0.0002934572985395789\n",
      "iter=65500, loss=0.00023650772345717996\n",
      "iter=65600, loss=0.00024286469852086157\n",
      "iter=65700, loss=0.00025790531071834266\n",
      "iter=65800, loss=0.000282796798273921\n",
      "iter=65900, loss=0.00024104758631438017\n",
      "iter=66000, loss=0.0002656193100847304\n",
      "iter=66100, loss=0.00027420721016824245\n",
      "iter=66200, loss=0.000270194053882733\n",
      "iter=66300, loss=0.00024001303245313466\n",
      "iter=66400, loss=0.0003299289382994175\n",
      "iter=66500, loss=0.00032276264391839504\n",
      "iter=66600, loss=0.00026055268244817853\n",
      "iter=66700, loss=0.0002274426369694993\n",
      "iter=66800, loss=0.00028002343606203794\n",
      "iter=66900, loss=0.0002564751193858683\n",
      "iter=67000, loss=0.0002670150715857744\n",
      "iter=67100, loss=0.0002514509833417833\n",
      "iter=67200, loss=0.00029550454928539693\n",
      "iter=67300, loss=0.00024416326778009534\n",
      "iter=67400, loss=0.00023804139345884323\n",
      "iter=67500, loss=0.0002971403591800481\n",
      "iter=67600, loss=0.0003302882832940668\n",
      "iter=67700, loss=0.00026493630139157176\n",
      "iter=67800, loss=0.00023814605083316565\n",
      "iter=67900, loss=0.00028976178145967424\n",
      "iter=68000, loss=0.0002187307400163263\n",
      "iter=68100, loss=0.00029516438371501863\n",
      "iter=68200, loss=0.00025841849856078625\n",
      "iter=68300, loss=0.0002529849298298359\n",
      "iter=68400, loss=0.0002601725864224136\n",
      "iter=68500, loss=0.00024337010108865798\n",
      "iter=68600, loss=0.00024960594600997865\n",
      "iter=68700, loss=0.00029086595168337226\n",
      "iter=68800, loss=0.000254089361988008\n",
      "iter=68900, loss=0.00023555384541396052\n",
      "iter=69000, loss=0.00023252256505656987\n",
      "iter=69100, loss=0.0002598183637019247\n",
      "iter=69200, loss=0.0003240767982788384\n",
      "iter=69300, loss=0.0002447326551191509\n",
      "iter=69400, loss=0.0002541691646911204\n",
      "iter=69500, loss=0.00028083170764148235\n",
      "iter=69600, loss=0.0002456483489368111\n",
      "iter=69700, loss=0.00027462124126031995\n",
      "iter=69800, loss=0.0002439357340335846\n",
      "iter=69900, loss=0.0002518439432606101\n",
      "iter=70000, loss=0.000378947559511289\n",
      "iter=70100, loss=0.0003062298346776515\n",
      "iter=70200, loss=0.0002855741186067462\n",
      "iter=70300, loss=0.0003068320802412927\n",
      "iter=70400, loss=0.000267103489022702\n",
      "iter=70500, loss=0.0002587480121292174\n",
      "iter=70600, loss=0.00026880507357418537\n",
      "iter=70700, loss=0.0002680578618310392\n",
      "iter=70800, loss=0.00031068112002685666\n",
      "iter=70900, loss=0.0002894825884141028\n",
      "iter=71000, loss=0.0003541989135555923\n",
      "iter=71100, loss=0.00023491005413234234\n",
      "iter=71200, loss=0.0002267785312142223\n",
      "iter=71300, loss=0.0002424264675937593\n",
      "iter=71400, loss=0.00025235972134396434\n",
      "iter=71500, loss=0.0003012348897755146\n",
      "iter=71600, loss=0.0002532336220610887\n",
      "iter=71700, loss=0.00023468871950171888\n",
      "iter=71800, loss=0.00026542102568782866\n",
      "iter=71900, loss=0.0003097258449997753\n",
      "iter=72000, loss=0.00021735928021371365\n",
      "iter=72100, loss=0.0002776521141640842\n",
      "iter=72200, loss=0.00023599551059305668\n",
      "iter=72300, loss=0.00026607487234286964\n",
      "iter=72400, loss=0.0002637491561472416\n",
      "iter=72500, loss=0.0002900726976804435\n",
      "iter=72600, loss=0.0002525826566852629\n",
      "iter=72700, loss=0.0002615989651530981\n",
      "iter=72800, loss=0.00026795401936396956\n",
      "iter=72900, loss=0.00023383775260299444\n",
      "iter=73000, loss=0.0002400977973593399\n",
      "iter=73100, loss=0.00024176525766961277\n",
      "iter=73200, loss=0.0002900379477068782\n",
      "iter=73300, loss=0.00024806713918223977\n",
      "iter=73400, loss=0.00023370160488411784\n",
      "iter=73500, loss=0.00023814768064767122\n",
      "iter=73600, loss=0.00028204216505400836\n",
      "iter=73700, loss=0.0002842486428562552\n",
      "iter=73800, loss=0.0002684557985048741\n",
      "iter=73900, loss=0.00024295381444972008\n",
      "iter=74000, loss=0.00022079267364460975\n",
      "iter=74100, loss=0.0002574297832325101\n",
      "iter=74200, loss=0.0002296403981745243\n",
      "iter=74300, loss=0.00022550503490492702\n",
      "iter=74400, loss=0.0002328497648704797\n",
      "iter=74500, loss=0.0002706736559048295\n",
      "iter=74600, loss=0.0002535040839575231\n",
      "iter=74700, loss=0.0002468298771418631\n",
      "iter=74800, loss=0.00025698269018903375\n",
      "iter=74900, loss=0.0003309142484795302\n",
      "iter=75000, loss=0.0002892902120947838\n",
      "iter=75100, loss=0.00024941505398601294\n",
      "iter=75200, loss=0.0002511257480364293\n",
      "iter=75300, loss=0.0002518409746699035\n",
      "iter=75400, loss=0.00022197993530426174\n",
      "iter=75500, loss=0.000241813191678375\n",
      "iter=75600, loss=0.00020461097301449627\n",
      "iter=75700, loss=0.0002834442420862615\n",
      "iter=75800, loss=0.0002160728326998651\n",
      "iter=75900, loss=0.00024676445173099637\n",
      "iter=76000, loss=0.0002264689828734845\n",
      "iter=76100, loss=0.0002260108885820955\n",
      "iter=76200, loss=0.0002145285252481699\n",
      "iter=76300, loss=0.0002757346082944423\n",
      "iter=76400, loss=0.0002190857194364071\n",
      "iter=76500, loss=0.00026597955729812384\n",
      "iter=76600, loss=0.00021639188344124705\n",
      "iter=76700, loss=0.0002373847964918241\n",
      "iter=76800, loss=0.00021546932111959904\n",
      "iter=76900, loss=0.00024586624931544065\n",
      "iter=77000, loss=0.0002497071400284767\n",
      "iter=77100, loss=0.00023536950175184757\n",
      "iter=77200, loss=0.00025581836234778166\n",
      "iter=77300, loss=0.00025759421987459064\n",
      "iter=77400, loss=0.00024783064145594835\n",
      "iter=77500, loss=0.00022709838231094182\n",
      "iter=77600, loss=0.00024327763821929693\n",
      "iter=77700, loss=0.00023834186140447855\n",
      "iter=77800, loss=0.00023490640160162002\n",
      "iter=77900, loss=0.00022041449847165495\n",
      "iter=78000, loss=0.00022524746600538492\n",
      "iter=78100, loss=0.00023006214178167284\n",
      "iter=78200, loss=0.0002436133800074458\n",
      "iter=78300, loss=0.0002621890162117779\n",
      "iter=78400, loss=0.0002393240574747324\n",
      "iter=78500, loss=0.0002416599018033594\n",
      "iter=78600, loss=0.00024075323017314076\n",
      "iter=78700, loss=0.00023900521046016365\n",
      "iter=78800, loss=0.00023406982654705644\n",
      "iter=78900, loss=0.00026913656620308757\n",
      "iter=79000, loss=0.000247432675678283\n",
      "iter=79100, loss=0.00021307196584530175\n",
      "iter=79200, loss=0.00022134130995254964\n",
      "iter=79300, loss=0.00023553817300125957\n",
      "iter=79400, loss=0.0002417700015939772\n",
      "iter=79500, loss=0.00020567953470163047\n",
      "iter=79600, loss=0.00025744459708221257\n",
      "iter=79700, loss=0.00021917633421253413\n",
      "iter=79800, loss=0.00022052536951377988\n",
      "iter=79900, loss=0.00023597624385729432\n",
      "iter=80000, loss=0.00023627234622836113\n",
      "iter=80100, loss=0.0002482017152942717\n",
      "iter=80200, loss=0.00021449819905683398\n",
      "iter=80300, loss=0.00022896044538356364\n",
      "iter=80400, loss=0.00021371638285927474\n",
      "iter=80500, loss=0.0002246134536108002\n",
      "iter=80600, loss=0.00023408405832014978\n",
      "iter=80700, loss=0.00022994610480964184\n",
      "iter=80800, loss=0.00023808545665815473\n",
      "iter=80900, loss=0.00022286741295829415\n",
      "iter=81000, loss=0.00021565126371569932\n",
      "iter=81100, loss=0.00028071593260392547\n",
      "iter=81200, loss=0.00023734031128697097\n",
      "iter=81300, loss=0.00023920982494018972\n",
      "iter=81400, loss=0.00023831037105992436\n",
      "iter=81500, loss=0.00023412759765051305\n",
      "iter=81600, loss=0.00021461064170580357\n",
      "iter=81700, loss=0.00021169325918890536\n",
      "iter=81800, loss=0.000207681383471936\n",
      "iter=81900, loss=0.0002139110874850303\n",
      "iter=82000, loss=0.00020965447765775025\n",
      "iter=82100, loss=0.00022639149392489344\n",
      "iter=82200, loss=0.00022383066243492067\n",
      "iter=82300, loss=0.00021416973322629929\n",
      "iter=82400, loss=0.00021660761558450758\n",
      "iter=82500, loss=0.0002326692483620718\n",
      "iter=82600, loss=0.0002597070415504277\n",
      "iter=82700, loss=0.0002168695500586182\n",
      "iter=82800, loss=0.00022311296197585762\n",
      "iter=82900, loss=0.00021582507179118693\n",
      "iter=83000, loss=0.00021579107851721346\n",
      "iter=83100, loss=0.00023250174126587808\n",
      "iter=83200, loss=0.00025028252275660634\n",
      "iter=83300, loss=0.00022518089099321514\n",
      "iter=83400, loss=0.00022104577510617673\n",
      "iter=83500, loss=0.00021815477521158755\n",
      "iter=83600, loss=0.00021359213860705495\n",
      "iter=83700, loss=0.0002073703071800992\n",
      "iter=83800, loss=0.00020172222866676748\n",
      "iter=83900, loss=0.0002353678282815963\n",
      "iter=84000, loss=0.00022406523930840194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=84100, loss=0.00031138473423197865\n",
      "iter=84200, loss=0.0002737544709816575\n",
      "iter=84300, loss=0.00023470932501368225\n",
      "iter=84400, loss=0.00024266084074042737\n",
      "iter=84500, loss=0.00022319331765174866\n",
      "iter=84600, loss=0.0002964366867672652\n",
      "iter=84700, loss=0.00023257547582034022\n",
      "iter=84800, loss=0.00027724960818886757\n",
      "iter=84900, loss=0.0002069795154966414\n",
      "iter=85000, loss=0.00019455913570709527\n",
      "iter=85100, loss=0.00021704146638512611\n",
      "iter=85200, loss=0.00021850131452083588\n",
      "iter=85300, loss=0.00020028295693919063\n",
      "iter=85400, loss=0.00019846268696710467\n",
      "iter=85500, loss=0.00019665165746118873\n",
      "iter=85600, loss=0.00021514357649721205\n",
      "iter=85700, loss=0.0002102152066072449\n",
      "iter=85800, loss=0.00024382064293604344\n",
      "iter=85900, loss=0.00020399497589096427\n",
      "iter=86000, loss=0.00023462915851268917\n",
      "iter=86100, loss=0.00023577547108288854\n",
      "iter=86200, loss=0.00022697488020639867\n",
      "iter=86300, loss=0.00020771389245055616\n",
      "iter=86400, loss=0.0002604102483019233\n",
      "iter=86500, loss=0.00021776727226097137\n",
      "iter=86600, loss=0.00020379963098093867\n",
      "iter=86700, loss=0.0002616774872876704\n",
      "iter=86800, loss=0.0002202766772825271\n",
      "iter=86900, loss=0.00020412889716681093\n",
      "iter=87000, loss=0.00019373311079107225\n",
      "iter=87100, loss=0.0002059302933048457\n",
      "iter=87200, loss=0.00019634357886388898\n",
      "iter=87300, loss=0.00022576932678930461\n",
      "iter=87400, loss=0.00021751809981651604\n",
      "iter=87500, loss=0.0002148124622181058\n",
      "iter=87600, loss=0.00021327548893168569\n",
      "iter=87700, loss=0.00020426121773198247\n",
      "iter=87800, loss=0.00021431221102830023\n",
      "iter=87900, loss=0.000217782479012385\n",
      "iter=88000, loss=0.00019504963711369783\n",
      "iter=88100, loss=0.00020183573360554874\n",
      "iter=88200, loss=0.00019174448971170932\n",
      "iter=88300, loss=0.00020806276006624103\n",
      "iter=88400, loss=0.00019508114201016724\n",
      "iter=88500, loss=0.0002065168519038707\n",
      "iter=88600, loss=0.00020496651995927095\n",
      "iter=88700, loss=0.00020573096117004752\n",
      "iter=88800, loss=0.00020056511857546866\n",
      "iter=88900, loss=0.00021044480672571808\n",
      "iter=89000, loss=0.00022196174541022629\n",
      "iter=89100, loss=0.00020418707572389394\n",
      "iter=89200, loss=0.00018944501061923802\n",
      "iter=89300, loss=0.00019549235003069043\n",
      "iter=89400, loss=0.00018708969582803547\n",
      "iter=89500, loss=0.00018652713333722204\n",
      "iter=89600, loss=0.00022480494226329029\n",
      "iter=89700, loss=0.00019707462342921644\n",
      "iter=89800, loss=0.00018971905228681862\n",
      "iter=89900, loss=0.00018777840887196362\n",
      "iter=90000, loss=0.00018831179477274418\n",
      "iter=90100, loss=0.0002108047774527222\n",
      "iter=90200, loss=0.00019216796499677002\n",
      "iter=90300, loss=0.0002037338854279369\n",
      "iter=90400, loss=0.00020122237037867308\n",
      "iter=90500, loss=0.00020392166334204376\n",
      "iter=90600, loss=0.00021523117902688682\n",
      "iter=90700, loss=0.00021447503240779042\n",
      "iter=90800, loss=0.0002036017831414938\n",
      "iter=90900, loss=0.0002013699122471735\n",
      "iter=91000, loss=0.00021837037638761103\n",
      "iter=91100, loss=0.00020072660117875785\n",
      "iter=91200, loss=0.00020854661124758422\n",
      "iter=91300, loss=0.0002106542233377695\n",
      "iter=91400, loss=0.00020155678794253618\n",
      "iter=91500, loss=0.0002054981014225632\n",
      "iter=91600, loss=0.00021243879746180028\n",
      "iter=91700, loss=0.00021662458311766386\n",
      "iter=91800, loss=0.00020710693206638098\n",
      "iter=91900, loss=0.00020418157509993762\n",
      "iter=92000, loss=0.0002009430609177798\n",
      "iter=92100, loss=0.00019597770005930215\n",
      "iter=92200, loss=0.00020236398268025368\n",
      "iter=92300, loss=0.0002003147528739646\n",
      "iter=92400, loss=0.00021729429136030376\n",
      "iter=92500, loss=0.00021989010565448552\n",
      "iter=92600, loss=0.00020625746401492506\n",
      "iter=92700, loss=0.00019889291434083134\n",
      "iter=92800, loss=0.00020542737911455333\n",
      "iter=92900, loss=0.00020402160589583218\n",
      "iter=93000, loss=0.00019992489251308143\n",
      "iter=93100, loss=0.000204873489565216\n",
      "iter=93200, loss=0.0002021306281676516\n",
      "iter=93300, loss=0.00020346930250525475\n",
      "iter=93400, loss=0.00019853522826451808\n",
      "iter=93500, loss=0.00019501392671372741\n",
      "iter=93600, loss=0.00019293643708806485\n",
      "iter=93700, loss=0.0001949369179783389\n",
      "iter=93800, loss=0.00019201991381123662\n",
      "iter=93900, loss=0.00020065880380570889\n",
      "iter=94000, loss=0.00019403352052904665\n",
      "iter=94100, loss=0.0001904028613353148\n",
      "iter=94200, loss=0.00018777693912852556\n",
      "iter=94300, loss=0.00018945519695989788\n",
      "iter=94400, loss=0.0001937185734277591\n",
      "iter=94500, loss=0.00019184211851097643\n",
      "iter=94600, loss=0.00018906751938629895\n",
      "iter=94700, loss=0.00018978692241944373\n",
      "iter=94800, loss=0.0001919629576150328\n",
      "iter=94900, loss=0.00019320206774864346\n",
      "iter=95000, loss=0.00018809328321367502\n",
      "iter=95100, loss=0.00018754848861135542\n",
      "iter=95200, loss=0.00019023939967155457\n",
      "iter=95300, loss=0.00019027243251912296\n",
      "iter=95400, loss=0.00018756123608909547\n",
      "iter=95500, loss=0.00018746611021924764\n",
      "iter=95600, loss=0.00019048061221837997\n",
      "iter=95700, loss=0.0001895147142931819\n",
      "iter=95800, loss=0.0001899846101878211\n",
      "iter=95900, loss=0.00019135104957967997\n",
      "iter=96000, loss=0.00019266444724053144\n",
      "iter=96100, loss=0.00019116062321700156\n",
      "iter=96200, loss=0.0001899620983749628\n",
      "iter=96300, loss=0.00018875961541198194\n",
      "iter=96400, loss=0.00018981723405886441\n",
      "iter=96500, loss=0.00019114883616566658\n",
      "iter=96600, loss=0.00019189636805094779\n",
      "iter=96700, loss=0.0001919770147651434\n",
      "iter=96800, loss=0.00019112367590423673\n",
      "iter=96900, loss=0.0001919831265695393\n",
      "iter=97000, loss=0.00019438708841335028\n",
      "iter=97100, loss=0.0001916731707751751\n",
      "iter=97200, loss=0.0001909742713905871\n",
      "iter=97300, loss=0.00019142162636853755\n",
      "iter=97400, loss=0.00018907798221334815\n",
      "iter=97500, loss=0.00019069990958087146\n",
      "iter=97600, loss=0.00019174748740624636\n",
      "iter=97700, loss=0.00019042444182559848\n",
      "iter=97800, loss=0.000193418629351072\n",
      "iter=97900, loss=0.0001902388466987759\n",
      "iter=98000, loss=0.00019070625421591103\n",
      "iter=98100, loss=0.00018980931781698018\n",
      "iter=98200, loss=0.00018862704746425152\n",
      "iter=98300, loss=0.00018900226859841496\n",
      "iter=98400, loss=0.00018910143990069628\n",
      "iter=98500, loss=0.00018894500681199133\n",
      "iter=98600, loss=0.00018901473958976567\n",
      "iter=98700, loss=0.00018998094310518354\n",
      "iter=98800, loss=0.00019008053641300648\n",
      "iter=98900, loss=0.00018941787129733711\n",
      "iter=99000, loss=0.00018964118498843163\n",
      "iter=99100, loss=0.00018976614228449762\n",
      "iter=99200, loss=0.00018968494259752333\n",
      "iter=99300, loss=0.00018943805480375886\n",
      "iter=99400, loss=0.00019002400222234428\n",
      "iter=99500, loss=0.0001898236951092258\n",
      "iter=99600, loss=0.0001899559865705669\n",
      "iter=99700, loss=0.0001898282062029466\n",
      "iter=99800, loss=0.00018985311908181757\n",
      "iter=99900, loss=0.0001898332848213613\n",
      "iter=100000, loss=0.00018983175687026232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize all TF variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Add op to save and restore\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Generate validation data\n",
    "y_arr_validate, x_true_arr_validate = generate_data(validation=True)\n",
    "\n",
    "if chkpt:\n",
    "    saver.restore(sess, checkpoint_path.format(run_id=run_id))\n",
    "\n",
    "# Train the network\n",
    "for i in tqdm_notebook(range(0, maximum_steps)):\n",
    "    if i%10 == 0:\n",
    "        y_arr, x_true_arr = generate_data()\n",
    "\n",
    "    _, merged_summary_result_train, global_step_result = sess.run([optimizer, merged_summary, global_step],\n",
    "                              feed_dict={x_true: x_true_arr,\n",
    "                                         y_rt: y_arr,\n",
    "                                         is_training: True})\n",
    "\n",
    "    if i>0 and (i+1)%print_freq == 0:\n",
    "        loss_result, merged_summary_result, global_step_result = sess.run([loss, merged_summary, global_step],\n",
    "                              feed_dict={x_true: x_true_arr_validate,\n",
    "                                         y_rt: y_arr_validate,\n",
    "                                         is_training: False})\n",
    "\n",
    "        train_summary_writer.add_summary(merged_summary_result_train, global_step_result)\n",
    "        test_summary_writer.add_summary(merged_summary_result, global_step_result)\n",
    "\n",
    "        print('iter={}, loss={}'.format(global_step_result, loss_result))\n",
    "\n",
    "    if i>0 and (i+1)%1000 == 0:\n",
    "        saver.save(sess, checkpoint_path.format(run_id=run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
