{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/volatile/home/Zaccharie/workspace/fastmri-reproducible-benchmark\n"
     ]
    }
   ],
   "source": [
    "%cd ../../fastmri-reproducible-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Learned primal method.\"\"\"\n",
    "%matplotlib nbagg\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from pdnet_crop import tf_op, tf_adj_op, tf_crop\n",
    "from data import MaskedUntouched2DAllLoadedSequence, MaskedUntouched2DSequence\n",
    "from utils import keras_psnr, keras_ssim\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "name = \"learned-primal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefining adler's prelu\n",
    "# https://github.com/adler-j/adler/blob/master/adler/tensorflow/activation.py\n",
    "def prelu(_x, init=0.0, name='prelu', trainable=True):\n",
    "    with tf.variable_scope(name):\n",
    "        alphas = tf.get_variable('alphas',\n",
    "                                 shape=[int(_x.get_shape()[-1])],\n",
    "                                 initializer=tf.constant_initializer(init),\n",
    "                                 dtype=tf.float32,\n",
    "                                 trainable=True)\n",
    "        pos = tf.nn.relu(_x)\n",
    "        neg = -alphas * tf.nn.relu(-_x)\n",
    "\n",
    "        return pos + neg\n",
    "    \n",
    "# redefining adler's cosine decay\n",
    "# https://github.com/adler-j/adler/blob/master/adler/tensorflow/training.py\n",
    "def cosine_decay(learning_rate, global_step, maximum_steps,\n",
    "                 name=None):\n",
    "    from tensorflow.python.ops import math_ops\n",
    "    from tensorflow.python.framework import ops\n",
    "\n",
    "    if global_step is None:\n",
    "        raise ValueError(\"global_step is required for cosine_decay.\")\n",
    "    with ops.name_scope(name, \"CosineDecay\",\n",
    "                      [learning_rate, global_step, maximum_steps]) as name:\n",
    "        learning_rate = ops.convert_to_tensor(learning_rate, name=\"learning_rate\")\n",
    "        dtype = learning_rate.dtype\n",
    "        global_step = math_ops.cast(global_step, dtype)\n",
    "        maximum_steps = math_ops.cast(maximum_steps, dtype)\n",
    "\n",
    "        p = tf.mod(global_step / maximum_steps, 1)\n",
    "\n",
    "    return learning_rate * (0.5 + 0.5 * math_ops.cos(p * np.pi))\n",
    "    \n",
    "def apply_conv(x, filters=32):\n",
    "    return tf.layers.conv2d(x, filters=filters, kernel_size=3, padding='SAME',\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer(), use_bias=False,)\n",
    "\n",
    "def prelu_conv_complex(x, filters=16, name='prelu'):\n",
    "    with tf.variable_scope(name):\n",
    "        x_real = tf.math.real(x)\n",
    "        x_imag = tf.math.imag(x)   \n",
    "        with tf.variable_scope('real_conv', reuse=False):\n",
    "            res_real = prelu(apply_conv(x_real, filters=filters))\n",
    "        with tf.variable_scope('imag_conv', reuse=False):\n",
    "            res_imag = prelu(apply_conv(x_imag, filters=filters))\n",
    "    return tf.complex(res_real, res_imag)\n",
    "\n",
    "def prelu_conv_complex_concat(x, filters=32, name='prelu'):\n",
    "    with tf.variable_scope(name):\n",
    "        x_real = tf.math.real(x)\n",
    "        x_imag = tf.math.imag(x)   \n",
    "        res = prelu(apply_conv(tf.concat([x_real, x_imag], axis=-1), filters=filters))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User selected paramters\n",
    "n_iter = 10\n",
    "n_primal = 5\n",
    "n_dual = 5\n",
    "# tf params\n",
    "print_freq = 500\n",
    "chkpt = False\n",
    "maximum_steps = 10000\n",
    "logs_dir = 'logs_fastmri'\n",
    "checkpoint_path = 'fastmri_chkpt/chkpt_{run_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /volatile/home/Zaccharie/workspace/fastmri-reproducible-benchmark/pdnet_crop.py:63: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-268f3ce21880>:37: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /volatile/home/Zaccharie/workspace/learned_primal_dual/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "# define the model\n",
    "with tf.name_scope('placeholders'):\n",
    "    x_true = tf.placeholder(tf.float32, shape=[None, 320, 320, 1], name=\"x_true\")\n",
    "    y_rt = tf.placeholder(tf.complex64, shape=[None, 640, None, 1], name=\"y_rt\")\n",
    "    mask = tf.placeholder(tf.float32, shape=[None, 640, None], name=\"mask\")\n",
    "    is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "\n",
    "with tf.name_scope('MRI'):\n",
    "    with tf.name_scope('control'):\n",
    "        zero_filled = tf_adj_op([y_rt, mask])\n",
    "    with tf.name_scope('initial_values'):\n",
    "        primal = tf.concat([tf.zeros_like(y_rt, dtype=tf.complex64)] * n_primal, axis=-1)\n",
    "        dual = tf.concat([tf.zeros_like(y_rt, dtype=tf.complex64)] * n_dual, axis=-1)\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        with tf.variable_scope('dual_iterate_{}'.format(i)):\n",
    "            evalop = tf_op([primal[..., 1:2], mask])\n",
    "            update = tf.concat([dual, evalop, y_rt], axis=-1)\n",
    "            update = prelu_conv_complex_concat(update, name='prelu_1')\n",
    "            update = prelu_conv_complex_concat(update, name='prelu_2')\n",
    "            update = tf.complex(apply_conv(tf.math.real(update), filters=n_dual), apply_conv(tf.math.imag(update), filters=n_dual))\n",
    "            dual = dual + update\n",
    "\n",
    "        with tf.variable_scope('primal_iterate_{}'.format(i)):\n",
    "            evalop = tf_adj_op([dual[..., 0:1], mask])\n",
    "            update = tf.concat([primal, evalop], axis=-1)\n",
    "\n",
    "            update = prelu_conv_complex_concat(update, name='prelu_1')\n",
    "            update = prelu_conv_complex_concat(update, name='prelu_2')\n",
    "            update = tf.complex(apply_conv(tf.math.real(update), filters=n_primal), apply_conv(tf.math.imag(update), filters=n_primal))\n",
    "            primal = primal + update\n",
    "\n",
    "    x_result = primal[..., 0:1]\n",
    "    x_result = tf.math.abs(x_result)\n",
    "    x_result = tf_crop(x_result)\n",
    "\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    residual = x_result - x_true\n",
    "    squared_error = tf.math.real(residual)**2 + tf.math.imag(residual)**2\n",
    "    loss = tf.reduce_mean(squared_error)\n",
    "\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    # Learning rate\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 1e-2\n",
    "    learning_rate = 1e-3\n",
    "    learning_rate = cosine_decay(starter_learning_rate,\n",
    "                                 global_step,\n",
    "                                 maximum_steps,\n",
    "                                 name='learning_rate')\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        opt_func = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                          beta2=0.99)\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), 1)\n",
    "        optimizer = opt_func.apply_gradients(zip(grads, tvars),\n",
    "                                             global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567435989\n"
     ]
    }
   ],
   "source": [
    "# Summaries\n",
    "run_id = str(int(time.time()))\n",
    "print(run_id)\n",
    "\n",
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('psnr', tf.reduce_mean(keras_psnr(x_true, x_result)))\n",
    "    tf.summary.scalar('ssim', tf.reduce_mean(keras_ssim(x_true, x_result)))\n",
    "\n",
    "    tf.summary.image('x_result', tf.abs(x_result), max_outputs=1)\n",
    "    tf.summary.image('x_true', tf.abs(x_true), max_outputs=1)\n",
    "    tf.summary.image('zero_filled', tf.abs(tf_crop(zero_filled)), max_outputs=1)\n",
    "    tf.summary.image('squared_error', squared_error, max_outputs=1)\n",
    "    tf.summary.image('residual', tf.abs(residual), max_outputs=1)\n",
    "\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    test_summary_writer = tf.summary.FileWriter(logs_dir + f'/test_{run_id}')\n",
    "    train_summary_writer = tf.summary.FileWriter(logs_dir + f'/train_{run_id}', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "train_path = '/media/Zaccharie/UHRes/singlecoil_train/singlecoil_train/'\n",
    "val_path = '/media/Zaccharie/UHRes/singlecoil_val/'\n",
    "test_path = '/media/Zaccharie/UHRes/singlecoil_test/'\n",
    "\n",
    "n_samples_train = 34742\n",
    "n_samples_val = 7135\n",
    "\n",
    "n_volumes_train = 973\n",
    "n_volumes_val = 199\n",
    "\n",
    "# generators\n",
    "AF = 4\n",
    "# MaskShifted2DSequence, MaskShiftedSingleImage2DSequence, MaskedUntouched2DSequence\n",
    "train_gen = MaskedUntouched2DAllLoadedSequence(train_path, af=AF, inner_slices=1)\n",
    "val_gen = MaskedUntouched2DSequence(val_path, af=AF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c36002483d64190846ab20b20e2316c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=501, loss=2.2292662160694476e-10\n",
      "iter=1001, loss=6.701293298050359e-09\n",
      "iter=1501, loss=1.734375004724953e-10\n",
      "iter=2001, loss=2.0298562830589617e-09\n",
      "iter=2501, loss=3.3552047251639294e-10\n",
      "iter=3001, loss=2.143660943199066e-10\n",
      "iter=3501, loss=2.5833543637610035e-10\n",
      "iter=4001, loss=3.6143443793434926e-10\n",
      "iter=4501, loss=3.418285932088594e-10\n",
      "iter=5001, loss=1.643195912670592e-09\n"
     ]
    }
   ],
   "source": [
    "# Initialize all TF variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Add op to save and restore\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Generate validation data\n",
    "if chkpt:\n",
    "    saver.restore(sess, checkpoint_path.format(run_id=run_id))\n",
    "\n",
    "# Train the network\n",
    "for i in tqdm_notebook(range(0, maximum_steps)):\n",
    "#     [kspaces, mask_batch], images = train_gen[i % n_volumes_train]\n",
    "    [kspaces, mask_batch], images = train_gen[0]\n",
    "    _, merged_summary_result_train, global_step_result = sess.run([optimizer, merged_summary, global_step],\n",
    "                              feed_dict={x_true: images,\n",
    "                                         y_rt: kspaces,\n",
    "                                         mask: mask_batch,\n",
    "                                         is_training: True})\n",
    "    train_summary_writer.add_summary(merged_summary_result_train, global_step_result)\n",
    "    if i>0 and i%print_freq == 0:\n",
    "        [kspaces_val, mask_batch_val], images_val = val_gen[i % n_volumes_val]\n",
    "        loss_result, merged_summary_result, global_step_result = sess.run([loss, merged_summary, global_step],\n",
    "                              feed_dict={x_true: images_val,\n",
    "                                         y_rt: kspaces_val,\n",
    "                                         mask: mask_batch_val,\n",
    "                                         is_training: False})\n",
    "\n",
    "        \n",
    "        test_summary_writer.add_summary(merged_summary_result, global_step_result)\n",
    "\n",
    "        print('iter={}, loss={}'.format(global_step_result, loss_result))\n",
    "\n",
    "\n",
    "    if i>0 and (i+1)%1000 == 0:\n",
    "        saver.save(sess, checkpoint_path.format(run_id=run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
